# Recognising Quick, Draw! Sketches with Deep Learning

**Introduction**

Sketch recognition is a difficult task in computer vision due to the abstract and messy nature of human-drawn images.  
This project explores how deep learning models can classify quick doodles from Googleâ€™s [Quick, Draw!](https://quickdraw.withgoogle.com/data) dataset.

We trained and compared five models â€” CNN, LeNet, AlexNet, ResNet18, and ConvNeXt â€” to recognise hand-drawn sketches of **apple**, **car**, **cat**, **dog**, and **flower**.  
Input images were originally 28Ã—28 grayscale and resized to 128Ã—128 RGB for compatibility with deeper architectures.

<p align="center">
  <img src="https://github.com/user-attachments/assets/fd38b150-ee45-4a2a-b5ec-73bcfca38bfa" width="500"/>
  <br>
  <em>Fig. 1. Quick, Draw! Sample Data</em>
</p>

### ğŸ“ Dataset

- Subset of Googleâ€™s open-source [Quick, Draw!](https://quickdraw.withgoogle.com/data) dataset  
- Each sketch is a 28Ã—28 grayscale image drawn in under 20 seconds  
- **Selected categories**: `apple`, `car`, `cat`, `dog`, `flower`  
- **600 samples per class** â†’ 3,000 total images  
- Images normalised to [0â€“1], converted to RGB, and resized to **128Ã—128**  
- Class labels encoded as integers (e.g. apple = 0, car = 1, etc.)

#### ğŸ”„ Data Splits

- 80% for training  
- 20% for validation  
- From validation: 20% reused as a test set

#### ğŸ§ª Preprocessing & Augmentation

**Training set:**
- Colour jitter (brightness, contrast, saturation)  
- Random horizontal flip  
- Random resized crop to 128Ã—128  
- Normalisation (ImageNet mean & std)

**Validation/Test sets:**
- Resize to 128Ã—128  
- Normalisation only
